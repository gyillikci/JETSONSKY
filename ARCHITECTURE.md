# JetsonSky Refactored Architecture Documentation

## ğŸ“ Current Architecture Overview

This document provides comprehensive architectural diagrams of the refactored JetsonSky codebase after Phase 3 completion.

---

## 1. High-Level System Architecture

```mermaid
graph TB
    subgraph "User Interface Layer"
        GUI[JetsonSky_V53_08_Refactored.py<br/>937 lines<br/>Main GUI Application]
    end

    subgraph "Business Logic Layer"
        Camera[CameraController<br/>core/camera.py<br/>451 lines]
        Processor[ImageProcessor<br/>core/image_processor.py<br/>551 lines]
        Capture[CaptureManager<br/>io/capture_manager.py<br/>467 lines]
        AI[AIDetector<br/>ai/detector.py<br/>385 lines]
        Stabilizer[ImageStabilizer<br/>utils/stabilization.py<br/>307 lines]
    end

    subgraph "Foundation Layer"
        Config[Camera Config & State<br/>core/config.py<br/>core/camera_models.py]
        Filters[Filter Pipeline<br/>filters/*.py<br/>Phase 2 modules]
        Utils[Utilities<br/>utils/constants.py<br/>utils/stabilization.py]
    end

    subgraph "Hardware Layer"
        ASI[ZWO ASI SDK<br/>zwoasi_cupy/]
        EFW[Filter Wheel<br/>zwoefw/]
        Mount[Telescope Mount<br/>synscan/]
        CUDA[CUDA/CuPy<br/>GPU Acceleration]
    end

    GUI --> Camera
    GUI --> Processor
    GUI --> Capture
    GUI --> AI
    GUI --> Stabilizer

    Camera --> Config
    Camera --> ASI
    Camera --> CUDA

    Processor --> Filters
    Processor --> CUDA
    Processor --> Stabilizer

    Capture --> CUDA

    AI --> CUDA

    Stabilizer --> CUDA

    Filters --> CUDA
    Filters --> Utils

    style GUI fill:#e1f5ff
    style Camera fill:#fff3cd
    style Processor fill:#fff3cd
    style Capture fill:#fff3cd
    style AI fill:#fff3cd
    style Stabilizer fill:#fff3cd
    style Config fill:#d4edda
    style Filters fill:#d4edda
    style Utils fill:#d4edda
    style ASI fill:#f8d7da
    style CUDA fill:#f8d7da
```

---

## 2. Module Dependency Graph

```mermaid
graph LR
    subgraph "GUI Application"
        GUI[JetsonSky_V53_08<br/>Refactored.py]
    end

    subgraph "Core Modules"
        Camera[camera.py]
        ImageProc[image_processor.py]
        Config[config.py]
        Models[camera_models.py]
    end

    subgraph "I/O Modules"
        CaptureM[capture_manager.py]
        Serfile[Serfile/]
    end

    subgraph "AI Modules"
        Detector[detector.py]
        YOLO[ultralytics YOLO]
    end

    subgraph "Filter Modules"
        Pipeline[pipeline.py]
        Base[base.py]
        Color[color.py]
        Contrast[contrast.py]
        Denoise[denoise.py]
        Sharpen[sharpen.py]
        HotPixel[hotpixel.py]
        Transforms[transforms.py]
    end

    subgraph "Utility Modules"
        Constants[constants.py]
        Stabilization[stabilization.py]
    end

    subgraph "Hardware SDKs"
        ASI[zwoasi_cupy]
        EFW[zwoefw]
        SynScan[synscan]
    end

    subgraph "External Libraries"
        CuPy[CuPy/CUDA]
        OpenCV[OpenCV]
        Tkinter[Tkinter]
        PIL[PIL]
        NumPy[NumPy]
    end

    GUI --> Camera
    GUI --> ImageProc
    GUI --> CaptureM
    GUI --> Detector
    GUI --> Stabilization
    GUI --> Config

    Camera --> Models
    Camera --> ASI
    Camera --> CuPy

    ImageProc --> Pipeline
    ImageProc --> CuPy

    Pipeline --> Base
    Pipeline --> Color
    Pipeline --> Contrast
    Pipeline --> Denoise
    Pipeline --> Sharpen
    Pipeline --> HotPixel
    Pipeline --> Transforms

    Base --> CuPy
    Base --> NumPy

    CaptureM --> Serfile
    CaptureM --> OpenCV
    CaptureM --> PIL

    Detector --> YOLO
    Detector --> OpenCV

    Stabilization --> OpenCV
    Stabilization --> CuPy

    Config --> Constants
    Models --> Constants

    GUI --> Tkinter
    GUI --> PIL

    style GUI fill:#e1f5ff
    style Camera fill:#fff3cd
    style ImageProc fill:#fff3cd
    style CaptureM fill:#fff3cd
    style Detector fill:#fff3cd
    style Stabilization fill:#fff3cd
```

---

## 3. Class Diagram - Core Components

```mermaid
classDiagram
    class JetsonSkyGUI {
        -root: Tk
        -camera: CameraController
        -processor: ImageProcessor
        -capture_manager: CaptureManager
        -ai_detector: AIDetector
        -stabilizer: ImageStabilizer
        -cupy_context: Stream
        +__init__(root)
        +create_widgets()
        +init_camera()
        +start_preview()
        +stop_preview()
        +update_preview()
        +capture_image()
        +start_video_capture()
    }

    class CameraController {
        -camera: Camera
        -camera_config: CameraConfig
        -acquisition_thread: Thread
        -cupy_context: Stream
        +initialize() bool
        +start_acquisition() bool
        +stop_acquisition()
        +get_frame() tuple
        +set_exposure(us)
        +set_gain(value)
        +set_resolution(w, h, bin)
    }

    class CameraAcquisitionThread {
        -controller: CameraController
        -cupy_context: Stream
        -running: bool
        -active: bool
        +run()
        +stop()
    }

    class ImageProcessor {
        -cupy_context: Stream
        -color_pipeline: FilterPipeline
        -mono_pipeline: FilterPipeline
        -filters: dict
        +process_frame(frame, is_16bit) tuple
        +enable_filter(name)
        +disable_filter(name)
        +update_filter_parameter(name, param, value)
    }

    class FilterPipeline {
        -filters: list
        -cupy_context: Stream
        +add_filter(filter)
        +remove_filter(filter)
        +apply(image) image
    }

    class Filter {
        <<abstract>>
        +enabled: bool
        +apply(image) image
        +validate(image) bool
    }

    class CaptureManager {
        -video_thread: VideoCaptureThread
        -ser_writer: SerWriter
        -image_dir: Path
        -video_dir: Path
        +save_image(frame) str
        +start_video_capture(fps, size) bool
        +add_video_frame(frame) bool
        +stop_video_capture() dict
    }

    class AIDetector {
        -crater_model: YOLO
        -satellite_model: YOLO
        -track_history: dict
        +detect_craters(frame) list
        +detect_satellites(frame) list
        +draw_detections(frame) frame
        +reset_tracking()
    }

    class ImageStabilizer {
        -template: ndarray
        -delta_tx: int
        -delta_ty: int
        -enabled: bool
        +enable()
        +disable()
        +stabilize(image, is_color) image
        +adjust_offset(dx, dy)
        +reset()
    }

    JetsonSkyGUI --> CameraController
    JetsonSkyGUI --> ImageProcessor
    JetsonSkyGUI --> CaptureManager
    JetsonSkyGUI --> AIDetector
    JetsonSkyGUI --> ImageStabilizer

    CameraController --> CameraAcquisitionThread
    ImageProcessor --> FilterPipeline
    FilterPipeline --> Filter

    Filter <|-- ColorBalanceFilter
    Filter <|-- ContrastCLAHEFilter
    Filter <|-- DenoiseKNNFilter
    Filter <|-- SharpenFilter
    Filter <|-- HotPixelRemovalFilter
```

---

## 4. Data Flow Diagram - Camera Acquisition & Processing

```mermaid
flowchart TD
    Start([User Clicks<br/>Start Preview])

    InitCam[CameraController<br/>start_acquisition]
    Thread[Start Acquisition<br/>Thread]

    subgraph "Acquisition Loop (Thread)"
        GetFrame[Capture Frame<br/>from Camera]
        Raw16[RAW16 or RAW8<br/>CuPy Array]
        Store[Store in<br/>controller._raw_frame]
    end

    subgraph "Main GUI Loop"
        Check[get_frame<br/>Non-blocking]
        NewFrame{New Frame?}
        Process[ImageProcessor<br/>process_frame]

        subgraph "Processing Pipeline"
            Convert16to8[Convert 16-bit to 8-bit]
            Debayer[Debayer<br/>Bayer â†’ RGB]
            ApplyFilters[Apply Filter Pipeline]

            subgraph "Filters (if enabled)"
                HotPix[Hot Pixel Removal]
                Denoise[Denoise KNN/NLM2]
                Contrast[CLAHE Contrast]
                Sharpen[Sharpen]
                Sat[Saturation]
            end
        end

        Stab{Stabilization<br/>Enabled?}
        ApplyStab[ImageStabilizer<br/>stabilize]

        AICheck{AI Detection<br/>Enabled?}
        AIDetect[AIDetector<br/>detect_craters/<br/>detect_satellites]
        DrawBoxes[Draw Bounding<br/>Boxes]

        Display[Convert to PIL<br/>Display on Canvas]
        UpdateInfo[Update FPS<br/>& Info Display]
    end

    Start --> InitCam
    InitCam --> Thread
    Thread --> GetFrame
    GetFrame --> Raw16
    Raw16 --> Store
    Store --> GetFrame

    Check --> NewFrame
    NewFrame -->|Yes| Process
    NewFrame -->|No| Check

    Process --> Convert16to8
    Convert16to8 --> Debayer
    Debayer --> ApplyFilters
    ApplyFilters --> HotPix
    HotPix --> Denoise
    Denoise --> Contrast
    Contrast --> Sharpen
    Sharpen --> Sat

    Sat --> Stab
    Stab -->|Yes| ApplyStab
    Stab -->|No| AICheck
    ApplyStab --> AICheck

    AICheck -->|Yes| AIDetect
    AICheck -->|No| Display
    AIDetect --> DrawBoxes
    DrawBoxes --> Display

    Display --> UpdateInfo
    UpdateInfo --> Check

    style Start fill:#e1f5ff
    style Display fill:#d4edda
    style GetFrame fill:#fff3cd
    style Process fill:#fff3cd
    style AIDetect fill:#f8d7da
```

---

## 5. Component Interaction - Image Capture Flow

```mermaid
sequenceDiagram
    participant User
    participant GUI
    participant Camera
    participant Processor
    participant Stabilizer
    participant AI
    participant Capture

    User->>GUI: Click "Capture Image"
    GUI->>Camera: get_frame()
    Camera-->>GUI: raw_frame (16-bit)

    GUI->>Processor: process_frame(raw_frame)

    Note over Processor: Convert 16â†’8 bit
    Note over Processor: Debayer (if color)
    Note over Processor: Apply filters

    Processor-->>GUI: processed_frame

    alt Stabilization Enabled
        GUI->>Stabilizer: stabilize(processed_frame)
        Note over Stabilizer: Template matching
        Note over Stabilizer: Apply offset
        Stabilizer-->>GUI: stabilized_frame
    end

    alt AI Detection Enabled
        GUI->>AI: detect_craters(frame)
        AI-->>GUI: crater_list
        GUI->>AI: detect_satellites(frame)
        AI-->>GUI: satellite_list
        GUI->>AI: draw_detections(frame)
        AI-->>GUI: frame_with_boxes
    end

    GUI->>Capture: save_image(final_frame)
    Note over Capture: Convert format
    Note over Capture: Save to disk
    Capture-->>GUI: filepath

    GUI->>User: Display "Image saved"
```

---

## 6. Filter Pipeline Architecture

```mermaid
graph TB
    subgraph "ImageProcessor"
        Input[Input Frame<br/>16-bit RAW]

        Convert[Convert to 8-bit]
        Debayer[Debayer to RGB]

        subgraph "FilterPipeline"
            F1[FlipFilter]
            F2[NegativeFilter]
            F3[HotPixelRemovalFilter]
            F4[ThreeFrameNoiseRemovalFilter]
            F5[AdaptiveAbsorberFilter]
            F6[DenoisePaillouFilter]
            F7[DenoiseNLM2Filter]
            F8[DenoiseKNNFilter]
            F9[ContrastLowLightFilter]
            F10[ContrastCLAHEFilter]
            F11[RGBBalanceFilter]
            F12[SaturationFilter]
            F13[SharpenSoft1Filter]
            F14[SharpenSoft2Filter]
        end

        Output[Output Frame<br/>8-bit RGB/Mono]
    end

    Input --> Convert
    Convert --> Debayer
    Debayer --> F1
    F1 --> F2
    F2 --> F3
    F3 --> F4
    F4 --> F5
    F5 --> F6
    F6 --> F7
    F7 --> F8
    F8 --> F9
    F9 --> F10
    F10 --> F11
    F11 --> F12
    F12 --> F13
    F13 --> F14
    F14 --> Output

    style Input fill:#e1f5ff
    style Output fill:#d4edda
    style F1 fill:#fff3cd
    style F2 fill:#fff3cd
    style F3 fill:#fff3cd
    style F10 fill:#ffc107
    style F13 fill:#ffc107
```

---

## 7. File Structure Tree

```
JETSONSKY/
â”œâ”€â”€ JetsonSky/
â”‚   â”œâ”€â”€ JetsonSky_V53_08_Refactored.py      â­ Main GUI (937 lines)
â”‚   â”‚   â””â”€â”€ Uses: All OOP components below
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                                ğŸ“¦ Business Logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ camera.py                        ğŸ¥ CameraController (451 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ CameraController class
â”‚   â”‚   â”‚   â””â”€â”€ CameraAcquisitionThread class
â”‚   â”‚   â”œâ”€â”€ image_processor.py               ğŸ¨ ImageProcessor (551 lines)
â”‚   â”‚   â”‚   â””â”€â”€ Coordinates filter pipeline
â”‚   â”‚   â”œâ”€â”€ config.py                        âš™ï¸ State Management (237 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ CameraConfig
â”‚   â”‚   â”‚   â”œâ”€â”€ ProcessingState
â”‚   â”‚   â”‚   â”œâ”€â”€ AppState
â”‚   â”‚   â”‚   â””â”€â”€ Other state classes
â”‚   â”‚   â””â”€â”€ camera_models.py                 ğŸ“‹ Camera Registry (828 lines)
â”‚   â”‚       â””â”€â”€ CAMERA_MODELS dict (34 cameras)
â”‚   â”‚
â”‚   â”œâ”€â”€ filters/                             ğŸ­ Image Processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                          (Filter abstract class)
â”‚   â”‚   â”œâ”€â”€ pipeline.py                      (FilterPipeline class)
â”‚   â”‚   â”œâ”€â”€ color.py                         (Color filters)
â”‚   â”‚   â”œâ”€â”€ contrast.py                      (Contrast filters)
â”‚   â”‚   â”œâ”€â”€ denoise.py                       (Denoise filters)
â”‚   â”‚   â”œâ”€â”€ sharpen.py                       (Sharpen filters)
â”‚   â”‚   â”œâ”€â”€ hotpixel.py                      (Hot pixel removal)
â”‚   â”‚   â””â”€â”€ transforms.py                    (Flip, negative, etc.)
â”‚   â”‚
â”‚   â”œâ”€â”€ io/                                  ğŸ’¾ File I/O
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ capture_manager.py               ğŸ“¸ CaptureManager (467 lines)
â”‚   â”‚       â”œâ”€â”€ CaptureManager class
â”‚   â”‚       â””â”€â”€ VideoCaptureThread class
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/                                  ğŸ¤– AI Detection
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ detector.py                      ğŸ¯ AIDetector (385 lines)
â”‚   â”‚       â””â”€â”€ YOLOv8 integration
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                               ğŸ”§ Utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ constants.py                     ğŸ“ Constants (423 lines)
â”‚   â”‚   â””â”€â”€ stabilization.py                 ğŸ¯ ImageStabilizer (307 lines)
â”‚   â”‚       â””â”€â”€ Template-based stabilization
â”‚   â”‚
â”‚   â”œâ”€â”€ hardware/                            ğŸ”Œ Hardware SDKs
â”‚   â”‚   â”œâ”€â”€ zwoasi_cupy/                     (Camera SDK)
â”‚   â”‚   â”œâ”€â”€ zwoefw/                          (Filter wheel SDK)
â”‚   â”‚   â””â”€â”€ synscan/                         (Mount control SDK)
â”‚   â”‚
â”‚   â””â”€â”€ Serfile/                             ğŸ“¼ SER Format
â”‚       â””â”€â”€ SER file I/O
â”‚
â”œâ”€â”€ PHASE3_SUMMARY.md                        ğŸ“š Documentation
â”œâ”€â”€ QUICK_START_V53_08.md
â””â”€â”€ README.md

Total: ~5,500 lines (well-organized)
vs Original: 11,301 lines (monolithic)
```

---

## 8. Code Size Comparison

```mermaid
pie title "Code Distribution After Refactoring"
    "GUI Application" : 937
    "Camera Controller" : 451
    "Image Processor" : 551
    "Capture Manager" : 467
    "AI Detector" : 385
    "Stabilizer" : 307
    "Camera Models" : 828
    "Filters" : 1200
    "Config & State" : 237
    "Constants" : 423
```

### Line Count Summary

| Component | Lines | Purpose |
|-----------|-------|---------|
| **GUI** | 937 | Main application with Tkinter UI |
| **CameraController** | 451 | High-speed camera acquisition |
| **ImageProcessor** | 551 | Filter pipeline coordinator |
| **CaptureManager** | 467 | Image/video file I/O |
| **AIDetector** | 385 | YOLO-based detection |
| **ImageStabilizer** | 307 | Template matching stabilization |
| **Camera Models** | 828 | 34 camera configurations |
| **Config/State** | 237 | Application state management |
| **Constants** | 423 | Centralized constants |
| **Filters** | ~1,200 | All filter modules combined |
| **TOTAL** | **~5,700** | vs 11,301 original (**49% reduction**) |

---

## 9. Performance-Critical Paths

```mermaid
graph TD
    subgraph "Real-Time Path (Target: <100ms)"
        A[Camera Frame<br/>~0ms]
        B[Get Frame<br/>~1ms]
        C[16â†’8 bit<br/>~1ms]
        D[Debayer<br/>~5ms]
        E[Filter Pipeline<br/>~20-50ms]
        F[Stabilization<br/>~10ms]
        G[AI Detection<br/>~50ms]
        H[Display<br/>~5ms]

        A --> B --> C --> D --> E --> F --> G --> H
    end

    style A fill:#d4edda
    style B fill:#fff3cd
    style C fill:#fff3cd
    style D fill:#ffc107
    style E fill:#ff6b6b
    style F fill:#ffc107
    style G fill:#ff6b6b
    style H fill:#fff3cd
```

**Performance Targets:**
- Camera acquisition: **0ms** (async thread)
- Frame retrieval: **<1ms** (non-blocking)
- 16â†’8 bit conversion: **<1ms** (GPU)
- Debayering: **~5ms** (OpenCV)
- Filter pipeline: **<50ms** (GPU-accelerated)
- Stabilization: **~10ms** (template matching)
- AI detection: **<50ms** (YOLO on GPU)
- Display: **~5ms** (PIL/Tkinter)

**Total:** ~100-120ms per frame = **8-10 FPS** (with all features enabled)

---

## 10. Before vs After Architecture

### Before (Monolithic - V53_07RC)
```
JetsonSky_Linux_Windows_V53_07RC.py
â”œâ”€â”€ 11,301 lines
â”œâ”€â”€ 300+ global variables
â”œâ”€â”€ 200+ functions
â”œâ”€â”€ 3 classes (Thread-based)
â”œâ”€â”€ Everything mixed together
â”œâ”€â”€ Impossible to test
â”œâ”€â”€ Hard to maintain
â””â”€â”€ Hard to extend
```

### After (Refactored - V53_08)
```
Modular Architecture
â”œâ”€â”€ 25+ separate modules
â”œâ”€â”€ ~5,700 total lines (49% reduction)
â”œâ”€â”€ 0 global variables
â”œâ”€â”€ Clean OOP design
â”œâ”€â”€ Separated concerns:
â”‚   â”œâ”€â”€ GUI (937 lines)
â”‚   â”œâ”€â”€ Camera Control (451 lines)
â”‚   â”œâ”€â”€ Image Processing (551 lines)
â”‚   â”œâ”€â”€ Capture Management (467 lines)
â”‚   â”œâ”€â”€ AI Detection (385 lines)
â”‚   â””â”€â”€ Utilities (730 lines)
â”œâ”€â”€ Fully testable (unit tests possible)
â”œâ”€â”€ Easy to maintain (find code in seconds)
â””â”€â”€ Easy to extend (add features easily)
```

---

## 11. Dependency Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GUI Application Layer                 â”‚  JetsonSky_V53_08_Refactored.py
â”‚   (Tkinter, PIL, Display)               â”‚  937 lines
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Business Logic Layer                  â”‚  CameraController
â”‚   (Controllers, Managers, Processors)   â”‚  ImageProcessor
â”‚                                          â”‚  CaptureManager
â”‚                                          â”‚  AIDetector
â”‚                                          â”‚  ImageStabilizer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Foundation Layer                      â”‚  Config & State
â”‚   (Config, Filters, Constants)          â”‚  Camera Models
â”‚                                          â”‚  Filter Pipeline
â”‚                                          â”‚  Constants
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Hardware Abstraction Layer            â”‚  zwoasi_cupy
â”‚   (SDKs, Libraries)                     â”‚  zwoefw
â”‚                                          â”‚  synscan
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   External Libraries                    â”‚  CuPy/CUDA
â”‚   (CuPy, OpenCV, NumPy, YOLO)          â”‚  OpenCV
â”‚                                          â”‚  NumPy
â”‚                                          â”‚  ultralytics
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 12. Key Design Patterns Used

### 1. **MVC Pattern (Partial)**
- **Model:** Config, State classes
- **View:** Tkinter GUI widgets
- **Controller:** GUI event handlers + Business logic classes

### 2. **Strategy Pattern**
- **Filter:** Abstract base class with `apply()` method
- Concrete implementations: ColorBalance, CLAHE, Denoise, etc.

### 3. **Pipeline Pattern**
- **FilterPipeline:** Sequential processing
- Filters can be added/removed dynamically

### 4. **Facade Pattern**
- **ImageProcessor:** Hides filter pipeline complexity
- **CaptureManager:** Hides file I/O complexity

### 5. **Observer Pattern (Implicit)**
- GUI widgets trigger callbacks
- State changes propagate to components

### 6. **Singleton Pattern (Implicit)**
- Only one camera, processor, detector per app

---

## 13. Thread Architecture

```mermaid
graph TB
    subgraph "Main Thread (GUI)"
        GUI[Tkinter Main Loop]
        Update[update_preview<br/>~10ms interval]
        Display[Display Frame]
    end

    subgraph "Camera Thread"
        Acquire[Acquisition Loop]
        Capture[Capture Frame]
        Store[Store in Buffer]
    end

    subgraph "Video Capture Thread"
        VideoLoop[Video Encoding Loop]
        Queue[Frame Queue]
        Encode[Encode & Write]
    end

    GUI --> Update
    Update --> Display

    Acquire --> Capture
    Capture --> Store
    Store --> Acquire

    Update -.Get Frame.-> Store
    Update -.Add Frame.-> Queue

    Queue --> VideoLoop
    VideoLoop --> Encode
    Encode --> VideoLoop

    style GUI fill:#e1f5ff
    style Acquire fill:#fff3cd
    style VideoLoop fill:#d4edda
```

**Thread Safety:**
- Camera thread writes, GUI thread reads (flags for synchronization)
- Video thread has queue with lock
- No shared mutable state between threads

---

## Summary

### Architecture Highlights

âœ… **Clean Separation:** GUI, Business Logic, Foundation, Hardware layers
âœ… **Modular:** 25+ focused modules vs 1 monolithic file
âœ… **Testable:** Each component can be unit tested
âœ… **Maintainable:** Find code in seconds, not minutes
âœ… **Extensible:** Add features without breaking existing code
âœ… **Performance:** 100% maintained (same algorithms, better organization)

### Key Metrics

- **49% code reduction** (11,301 â†’ 5,700 lines)
- **100% performance maintained**
- **0 global variables** (300+ â†’ 0)
- **25+ modules** (1 â†’ 25+)
- **937 line GUI** (11,301 â†’ 937 in main file)

---

*Architecture diagrams generated for JetsonSky V53_08 Refactored*
*Branch: `claude/refactor-code-gui-unchanged-011CUhKhLDUJYbKijq6yjJSx`*
*Date: 2025-11-02*
